"""
PDF Parser for extracting call data from PDF reports.
Parses PDFs generated by PyFPDF containing call analysis data.
"""
import pdfplumber
import re
from datetime import datetime
from typing import Dict, Optional, Any
import io


def parse_pdf_from_bytes(pdf_bytes: bytes, filename: str) -> Optional[Dict[str, Any]]:
    """
    Parse a PDF file from bytes and extract call data.
    
    Args:
        pdf_bytes: PDF file content as bytes
        filename: Original filename (used for metadata extraction)
    
    Returns:
        Dictionary with parsed call data, or None if parsing fails
    """
    try:
        pdf_file = io.BytesIO(pdf_bytes)
        with pdfplumber.open(pdf_file) as pdf:
            # Extract all text from all pages
            full_text = "\n".join([page.extract_text() or "" for page in pdf.pages])
            
            if not full_text.strip():
                return None
            
            # Parse the data from text
            parsed_data = extract_data_from_text(full_text, filename)
            return parsed_data
            
    except Exception as e:
        print(f"Error parsing PDF {filename}: {e}")
        return None


def extract_data_from_text(text: str, filename: str) -> Dict[str, Any]:
    """
    Extract structured data from PDF text content.
    
    This function uses regex patterns to find key-value pairs and structured data
    in the PDF text. Adjust patterns based on actual PDF format.
    """
    data = {}
    
    # Extract metadata from filename if possible
    # Format: YYYYMMDD_HHMMSS_TYIO-email-phone-IN.pdf
    filename_parts = filename.replace('.pdf', '').split('_')
    if len(filename_parts) >= 2:
        try:
            date_str = filename_parts[0]  # YYYYMMDD
            time_str = filename_parts[1]  # HHMMSS
            date_raw = f"{date_str[4:6]}{date_str[6:8]}{date_str[0:4]}"  # Convert to MMDDYYYY
            call_date = datetime.strptime(date_str, "%Y%m%d")
            call_time = f"{time_str[0:2]}:{time_str[2:4]}:{time_str[4:6]}"
            data['date_raw'] = date_raw
            data['call_date'] = call_date
            data['time'] = call_time
        except:
            pass
    
    # Extract email and phone from filename if present
    if len(filename_parts) >= 3:
        email_phone = filename_parts[2]
        # Try to extract email (before @) and phone
        if '@' in email_phone:
            parts = email_phone.split('-')
            if len(parts) >= 2:
                data['agent'] = parts[1].split('@')[0] if '@' in parts[1] else parts[1]
    
    # Common patterns to look for in PDF text
    # Adjust these based on actual PDF structure
    
    # Look for emotion counts
    emotion_patterns = {
        'happy': r'(?i)(?:happy|happiness)[:\s]+(\d+)',
        'angry': r'(?i)(?:angry|anger)[:\s]+(\d+)',
        'sad': r'(?i)(?:sad|sadness)[:\s]+(\d+)',
        'neutral': r'(?i)(?:neutral)[:\s]+(\d+)',
    }
    
    for emotion, pattern in emotion_patterns.items():
        match = re.search(pattern, text)
        if match:
            try:
                data[emotion] = int(match.group(1))
            except:
                data[emotion] = 0
        else:
            data[emotion] = 0
    
    # Look for average happiness value
    happiness_patterns = [
        r'(?i)(?:average\s+)?happiness[:\s]+(\d+\.?\d*)%?',
        r'(?i)avg\s+happiness[:\s]+(\d+\.?\d*)%?',
        r'(?i)happiness\s+score[:\s]+(\d+\.?\d*)%?',
    ]
    
    for pattern in happiness_patterns:
        match = re.search(pattern, text)
        if match:
            try:
                data['average_happiness_value'] = float(match.group(1))
                break
            except:
                pass
    
    # If not found, calculate from emotion counts
    if 'average_happiness_value' not in data:
        total_emotions = sum([data.get(e, 0) for e in ['happy', 'angry', 'sad', 'neutral']])
        if total_emotions > 0:
            data['average_happiness_value'] = (data.get('happy', 0) / total_emotions) * 100
        else:
            data['average_happiness_value'] = 0.0
    
    # Look for low confidences
    confidence_patterns = [
        r'(?i)(?:low\s+)?confidence[:\s]+(\d+\.?\d*)%?',
        r'(?i)confidence\s+level[:\s]+(\d+\.?\d*)%?',
    ]
    
    for pattern in confidence_patterns:
        match = re.search(pattern, text)
        if match:
            try:
                data['low_confidences'] = float(match.group(1))
                break
            except:
                pass
    
    if 'low_confidences' not in data:
        data['low_confidences'] = 0.0
    
    # Look for call duration or speaking time
    duration_patterns = [
        r'(?i)(?:call\s+)?duration[:\s]+(\d+):(\d+):(\d+)',
        r'(?i)(?:call\s+)?duration[:\s]+(\d+):(\d+)',
        r'(?i)(?:total\s+)?time[:\s]+(\d+):(\d+):(\d+)',
    ]
    
    speaking_time = {}
    for pattern in duration_patterns:
        matches = re.finditer(pattern, text)
        for match in matches:
            try:
                if len(match.groups()) == 3:
                    hours, minutes, seconds = map(int, match.groups())
                    total_seconds = hours * 3600 + minutes * 60 + seconds
                else:
                    minutes, seconds = map(int, match.groups())
                    total_seconds = minutes * 60 + seconds
                
                # Try to identify speaker (agent/customer)
                context = text[max(0, match.start()-50):match.end()+50].lower()
                if 'agent' in context:
                    speaking_time['agent'] = f"{minutes}:{seconds:02d}"
                elif 'customer' in context or 'caller' in context:
                    speaking_time['customer'] = f"{minutes}:{seconds:02d}"
                else:
                    speaking_time['total'] = f"{minutes}:{seconds:02d}"
            except:
                pass
    
    if speaking_time:
        data['speaking_time_per_speaker'] = speaking_time
    
    # Extract company name (look for common patterns)
    company_patterns = [
        r'(?i)company[:\s]+([A-Za-z0-9\s]+)',
        r'(?i)client[:\s]+([A-Za-z0-9\s]+)',
    ]
    
    for pattern in company_patterns:
        match = re.search(pattern, text)
        if match:
            company = match.group(1).strip()
            # Clean up common suffixes
            company = re.sub(r'\s+', ' ', company)
            if company and len(company) < 50:  # Reasonable length check
                data['company'] = company
                break
    
    # Extract agent name if not from filename
    if 'agent' not in data:
        agent_patterns = [
            r'(?i)agent[:\s]+([A-Za-z0-9\s]+)',
            r'(?i)representative[:\s]+([A-Za-z0-9\s]+)',
        ]
        
        for pattern in agent_patterns:
            match = re.search(pattern, text)
            if match:
                agent = match.group(1).strip()
                agent = re.sub(r'\s+', ' ', agent)
                if agent and len(agent) < 50:
                    data['agent'] = agent
                    break
    
    # Generate call_id from filename if not found
    if 'call_id' not in data:
        data['call_id'] = filename.replace('.pdf', '').replace('%', '_')
    
    # Set defaults for missing fields
    if 'company' not in data:
        data['company'] = 'Unknown'
    if 'agent' not in data:
        data['agent'] = 'Unknown'
    
    return data

