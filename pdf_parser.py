"""
PDF Parser for extracting call data from PDF reports.
Parses PDFs generated by PyFPDF containing call analysis data.
"""
import pdfplumber
import re
from datetime import datetime
from typing import Dict, Optional, Any
import io
from urllib.parse import unquote


def parse_pdf_from_bytes(pdf_bytes: bytes, filename: str) -> Optional[Dict[str, Any]]:
    """
    Parse a PDF file from bytes and extract call data.
    
    Args:
        pdf_bytes: PDF file content as bytes
        filename: Original filename (used for metadata extraction)
    
    Returns:
        Dictionary with parsed call data, or None if parsing fails
    """
    try:
        pdf_file = io.BytesIO(pdf_bytes)
        with pdfplumber.open(pdf_file) as pdf:
            # Extract all text from all pages
            full_text = "\n".join([page.extract_text() or "" for page in pdf.pages])
            
            if not full_text.strip():
                return None
            
            # Parse the data from text
            parsed_data = extract_data_from_text(full_text, filename)
            return parsed_data
            
    except Exception as e:
        print(f"Error parsing PDF {filename}: {e}")
        return None


def extract_data_from_text(text: str, filename: str) -> Dict[str, Any]:
    """
    Extract structured data from PDF text content.
    
    This function uses regex patterns to find key-value pairs and structured data
    in the PDF text. Handles QA report format.
    """
    data = {}
    
    # Decode URL-encoded filename (e.g., %40 -> @, %2B -> +)
    decoded_filename = unquote(filename)
    
    # Extract metadata from filename if possible
    # Format: YYYYMMDD_HHMMSS_TYIO-email-phone-IN.pdf
    filename_parts = decoded_filename.replace('.pdf', '').split('_')
    if len(filename_parts) >= 2:
        try:
            date_str = filename_parts[0]  # YYYYMMDD
            time_str = filename_parts[1]  # HHMMSS
            date_raw = f"{date_str[4:6]}{date_str[6:8]}{date_str[0:4]}"  # Convert to MMDDYYYY
            call_date = datetime.strptime(date_str, "%Y%m%d")
            call_time = f"{time_str[0:2]}:{time_str[2:4]}:{time_str[4:6]}"
            data['date_raw'] = date_raw
            data['call_date'] = call_date
            data['time'] = call_time
        except:
            pass
    
    # Extract agent from PDF text first (format: "BPO Agent 01", "BPO Agent 02", etc.)
    # Convert to "bpagent01", "bpagent02" format
    bpo_agent_match = re.search(r'(?i)BPO Agent\s*(\d+)', text)
    if bpo_agent_match:
        agent_number = bpo_agent_match.group(1)
        # Zero-pad to 2 digits (01, 02, 03, etc.)
        agent_number_padded = agent_number.zfill(2)
        data['agent'] = f"bpagent{agent_number_padded}"
    else:
        # Fall back to filename extraction if not found in PDF text
        if len(filename_parts) >= 3:
            email_phone = filename_parts[2]
            # Extract agent ID (e.g., bpagent030844482 from bpagent030844482@nextiva.com)
            # Handle both URL-encoded and normal formats
            if '@' in email_phone:
                # Split by @ and get the part before @
                agent_part = email_phone.split('@')[0]
                # Remove any prefixes like "TYIO-" or "bp"
                agent_part = re.sub(r'^[^-]*-', '', agent_part)  # Remove prefix before first -
                if agent_part:
                    data['agent'] = agent_part
            else:
                # Try to find agent pattern even without @
                agent_match = re.search(r'([a-z]*agent\d+)', email_phone, re.IGNORECASE)
                if agent_match:
                    data['agent'] = agent_match.group(1)
    
    # Extract Call ID from PDF text
    call_id_match = re.search(r'(?i)Call ID:\s*([^\n]+)', text)
    if call_id_match:
        data['call_id'] = call_id_match.group(1).strip()
    
    # Extract QA Score
    qa_score_match = re.search(r'(?i)QA Score:\s*(\d+\.?\d*)%?', text)
    if qa_score_match:
        try:
            data['qa_score'] = float(qa_score_match.group(1))
        except:
            data['qa_score'] = None
    else:
        data['qa_score'] = None
    
    # Extract Label
    label_match = re.search(r'(?i)Label:\s*(\w+)', text)
    if label_match:
        data['label'] = label_match.group(1).strip()
    else:
        data['label'] = None
    
    # Extract Reason
    reason_match = re.search(r'(?i)Reason:\s*([^\n]+)', text)
    if reason_match:
        data['reason'] = reason_match.group(1).strip()
    else:
        data['reason'] = None
    
    # Extract Outcome
    outcome_match = re.search(r'(?i)Outcome:\s*([^\n]+)', text)
    if outcome_match:
        data['outcome'] = outcome_match.group(1).strip()
    else:
        data['outcome'] = None
    
    # Extract Summary (multi-line, until next section)
    summary_match = re.search(r'(?i)Summary:\s*([^\n]+(?:\n(?!Strengths:)[^\n]+)*)', text)
    if summary_match:
        data['summary'] = summary_match.group(1).strip()
    else:
        data['summary'] = None
    
    # Extract Strengths
    strengths_match = re.search(r'(?i)Strengths:\s*([^\n]+(?:\n(?!Challenges:)[^\n]+)*)', text)
    if strengths_match:
        data['strengths'] = strengths_match.group(1).strip()
    else:
        data['strengths'] = None
    
    # Extract Challenges
    challenges_match = re.search(r'(?i)Challenges:\s*([^\n]+(?:\n(?!Coaching)[^\n]+)*)', text)
    if challenges_match:
        data['challenges'] = challenges_match.group(1).strip()
    else:
        data['challenges'] = None
    
    # Extract Coaching Suggestions (multi-line)
    coaching_match = re.search(r'(?i)Coaching Suggestions:\s*([^\n]+(?:\n(?!Rubric)[^\n]+)*)', text)
    if coaching_match:
        coaching_text = coaching_match.group(1).strip()
        # Split by lines starting with "-"
        data['coaching_suggestions'] = [line.strip().lstrip('- ').strip() for line in coaching_text.split('\n') if line.strip()]
    else:
        data['coaching_suggestions'] = []
    
    # Extract Rubric Details (all lines with format "CODE: Status" or "CODE: Status - Note")
    rubric_pattern = r'(\d+\.\d+\.\d+):\s*(Pass|Fail|N/A)(?:\s*-\s*([^\n]+))?'
    rubric_matches = re.findall(rubric_pattern, text)
    rubric_details = {}
    for code, status, note in rubric_matches:
        rubric_details[code] = {
            'status': status,
            'note': note.strip() if note else None
        }
    data['rubric_details'] = rubric_details
    
    # Calculate rubric statistics
    total_rubric_items = len(rubric_details)
    pass_count = sum(1 for r in rubric_details.values() if r['status'] == 'Pass')
    fail_count = sum(1 for r in rubric_details.values() if r['status'] == 'Fail')
    na_count = sum(1 for r in rubric_details.values() if r['status'] == 'N/A')
    
    data['rubric_pass_count'] = pass_count
    data['rubric_fail_count'] = fail_count
    data['rubric_na_count'] = na_count
    data['rubric_total_count'] = total_rubric_items
    
    # For backward compatibility, keep average_happiness_value as qa_score
    if data.get('qa_score') is not None:
        data['average_happiness_value'] = data['qa_score']
    else:
        data['average_happiness_value'] = 0.0
    
    # Legacy emotion fields (set to defaults for compatibility)
    data['happy'] = 0
    data['angry'] = 0
    data['sad'] = 0
    data['neutral'] = 1 if data.get('label', '').lower() == 'neutral' else 0
    
    # Look for Call Length (format: "Call Length: 2.58 min")
    call_length_match = re.search(r'(?i)Call Length:\s*(\d+\.?\d*)\s*min', text)
    if call_length_match:
        try:
            minutes = float(call_length_match.group(1))
            total_seconds = int(minutes * 60)
            # Store as speaking_time_per_speaker format for compatibility
            data['speaking_time_per_speaker'] = {
                'total': f"{int(minutes)}:{int((minutes % 1) * 60):02d}"
            }
        except:
            pass
    
    # Low confidences not needed - always set to 0
    data['low_confidences'] = 0.0
    
    # Company name is hardcoded to Jomashop
    data['company'] = 'Jomashop'
    
    # Generate call_id from filename if not found in text
    if 'call_id' not in data:
        data['call_id'] = filename.replace('.pdf', '').replace('%', '_')
    
    # Set default for missing agent field
    if 'agent' not in data:
        data['agent'] = 'Unknown'
    
    return data

